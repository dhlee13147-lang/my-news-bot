import asyncio
import os
import csv
import time
import telegram
import google.generativeai as genai
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# âœ… ì„¤ì •ê°’ (GitHub Secrets)
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

# Gemini AI ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

bot = telegram.Bot(token=TELEGRAM_TOKEN)
csv_file = 'sent_news.csv'

# âœ… ë‰´ìŠ¤ ë³¸ë¬¸ì„ ê°€ì ¸ì™€ì„œ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜
async def get_summary(title, url):
    try:
        prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì œëª©ì„ ì°¸ê³ í•˜ì—¬ ë‚´ìš©ì„ 2ë¬¸ì¥ìœ¼ë¡œ ì•„ì£¼ ì§§ê²Œ ìš”ì•½í•´ì¤˜. ì œëª©: {title}"
        response = model.generate_content(prompt)
        return response.text.strip()
    except:
        return "ìš”ì•½ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

# (ë‚˜ë¨¸ì§€ ë¡œë“œ/ì €ì¥ í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼)
def load_sent_articles():
    if not os.path.exists(csv_file): return set()
    with open(csv_file, 'r', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        return set(row[0] for row in reader)

def save_sent_article(url, title):
    with open(csv_file, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow([url, title])

def create_driver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

async def news_release():
    sent_urls = load_sent_articles()
    driver = create_driver()
    companies = ["ë”ì¦Œ", "dozn", "ì¹´ì¹´ì˜¤ë±…í¬", "ì¹´ì¹´ì˜¤í˜ì´", "ì˜¤í”ˆì—ì…‹", "ìŠ¤ìœ„ì¹˜ì›"]

    for company in companies:
        search_url = f'https://search.naver.com/search.naver?where=news&query="{company}"&sm=tab_opt&sort=1'
        driver.get(search_url)
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        news_anchors = soup.select('a:has(span.sds-comps-text)')

        for anchor in news_anchors[:3]: # ë„ˆë¬´ ë§ì´ ë³´ë‚´ë©´ AI í˜¸ì¶œì´ ë§ì•„ì§€ë¯€ë¡œ 3ê°œë¡œ ì œí•œ
            title_tag = anchor.select_one('span.sds-comps-text')
            title = title_tag.get_text(strip=True) if title_tag else ''
            url = anchor.get('href', '').strip()

            if not title or not url or url in sent_urls: continue
            
            # âœ… AI ìš”ì•½ ì‹¤í–‰
            summary = await get_summary(title, url)
            
            message = f"ğŸ“¢ [{company} ë‰´ìŠ¤]\n\nğŸ“Œ ì œëª©: {title}\n\nğŸ¤– AI ìš”ì•½: {summary}\n\nğŸ”— ë§í¬: {url}"
            
            try:
                await bot.send_message(chat_id=CHAT_ID, text=message)
                save_sent_article(url, title)
                sent_urls.add(url)
                await asyncio.sleep(2)
            except: pass
    driver.quit()

if __name__ == "__main__":
    asyncio.run(news_release())

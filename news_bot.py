import asyncio
import os
import csv
import time
import telegram
from google import genai # ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë³€ê²½
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# âœ… ì„¤ì •ê°’
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

# Gemini ìµœì‹  ì„¤ì • ë°©ì‹ (2026 ê¸°ì¤€)
client = genai.Client(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else None

bot = telegram.Bot(token=TELEGRAM_TOKEN)
csv_file = 'sent_news.csv'

# âœ… ë³¸ë¬¸ ì¶”ì¶œ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
def get_article_content(driver, url):
    try:
        driver.get(url)
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        paragraphs = soup.find_all(['p', 'div'], class_=['article_body', 'art_body', 'news_con', 'article_view'])
        if not paragraphs: paragraphs = soup.find_all('p')
        content = " ".join([p.get_text(strip=True) for p in paragraphs])
        return content[:2000]
    except:
        return ""

# âœ… AI ìš”ì•½ í•¨ìˆ˜ (ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „)
async def get_summary(title, content):
    if not client: return "API í‚¤ ì„¤ì • í•„ìš”"
    if len(content) < 100: return "ë³¸ë¬¸ ë‚´ìš© ë¶€ì¡±ìœ¼ë¡œ ìš”ì•½ ë¶ˆê°€"
    
    try:
        prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ 3ì¤„ ìš”ì•½í•´ì¤˜.\nì œëª©: {title}\në³¸ë¬¸: {content}"
        # ìµœì‹  ëª¨ë¸ gemini-2.0-flash ì‚¬ìš©
        response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
        return response.text.strip()
    except Exception as e:
        print(f"ìš”ì•½ ì—ëŸ¬: {e}")
        return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

# âœ… [ì¤‘ìš”] IndexError ë°©ì§€ ë¡œì§ì´ ì¶”ê°€ëœ í•¨ìˆ˜
def load_sent_articles():
    if not os.path.exists(csv_file): return set()
    sent_set = set()
    with open(csv_file, 'r', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        for row in reader:
            if row: # ì¤„ì— ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ ì½ìŒ (IndexError ë°©ì§€)
                sent_set.add(row[0])
    return sent_set

def save_sent_article(url, title):
    with open(csv_file, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow([url, title])

def create_driver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

async def news_release():
    sent_urls = load_sent_articles()
    driver = create_driver()
    companies = ["ë”ì¦Œ", "dozn", "ì¹´ì¹´ì˜¤ë±…í¬", "ì¹´ì¹´ì˜¤í˜ì´", "ì˜¤í”ˆì—ì…‹", "ìŠ¤ìœ„ì¹˜ì›"]

    for company in companies:
        search_url = f'https://search.naver.com/search.naver?where=news&query="{company}"&sm=tab_opt&sort=1'
        driver.get(search_url)
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        for item in soup.select('a.news_tit')[:2]:
            title = item.get_text(strip=True)
            url = item.get('href', '').strip()

            if not title or not url or url in sent_urls: continue
            
            content = get_article_content(driver, url)
            summary = await get_summary(title, content)
            
            message = f"ğŸ“¢ [{company}]\nğŸ“Œ {title}\n\nğŸ¤– AI ìš”ì•½:\n{summary}\n\nğŸ”— {url}"
            
            try:
                await bot.send_message(chat_id=CHAT_ID, text=message)
                save_sent_article(url, title)
                sent_urls.add(url)
                await asyncio.sleep(2)
            except: pass

    driver.quit()

if __name__ == "__main__":
    asyncio.run(news_release())

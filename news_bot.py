import asyncio
import os
import csv
import time
import telegram
from google import genai
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

def log(message):
    print(message, flush=True)

# âœ… ì„¤ì •ê°’
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

client = genai.Client(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else None
bot = telegram.Bot(token=TELEGRAM_TOKEN)
csv_file = 'sent_news.csv'

companies = ["ë”ì¦Œ", "dozn", "ì¹´ì¹´ì˜¤ë±…í¬", "ì¹´ì¹´ì˜¤í˜ì´", "ì˜¤í”ˆì—ì…‹", "ìŠ¤ìœ„ì¹˜ì›"]
exceptionalWords = ['ë­í‚¤íŒŒì´', 'ë³´í˜¸ì', 'ë¸Œëœë“œí‰íŒ', 'ë¸Œëœë“œ í‰íŒ', 'íŠ¸ë Œë“œì§€ìˆ˜', 'íŠ¸ë Œë“œ ì§€ìˆ˜', 'ë§í¬ë“œì¸']
exceptionalSites = ['n.news.naver.com', 'www.pinpointnews.co.kr', 'www.pointdaily.co.kr', 'cwn.kr', 'www.stardailynews.co.kr', 'www.raonnews.com']

def load_sent_articles():
    if not os.path.exists(csv_file): return set()
    sent_set = set()
    with open(csv_file, 'r', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        for row in reader:
            if row: sent_set.add(row[0])
    return sent_set

def save_sent_article(url, title):
    with open(csv_file, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow([url, title])

def get_article_content(driver, url):
    try:
        driver.get(url)
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        paragraphs = soup.find_all(['p', 'div'], class_=['article_body', 'news_con', 'article_view'])
        if not paragraphs: paragraphs = soup.find_all('p')
        content = " ".join([p.get_text(strip=True) for p in paragraphs])
        return content[:2000]
    except: return ""

# âœ… 429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì¬ì‹œë„ ë¡œì§ì´ ì¶”ê°€ëœ ìš”ì•½ í•¨ìˆ˜
async def get_summary(title, content):
    if not client: return "API í‚¤ ë¯¸ì„¤ì •"
    
    # 1ë¶„ë‹¹ ìš”ì²­ ì œí•œì„ í”¼í•˜ê¸° ìœ„í•´ ìš”ì²­ ì „ 5ì´ˆê°„ ëŒ€ê¸° (ë§¤ìš° ì¤‘ìš”!)
    await asyncio.sleep(6) 
    
    try:
        prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ 3ì¤„ ìš”ì•½í•´ì¤˜.\nì œëª©: {title}\në³¸ë¬¸: {content}"
        # ë¬´ë£Œ ë²„ì „ì—ì„œ ê°€ì¥ ì•ˆì •ì ì¸ gemini-1.5-flash ëª¨ë¸ ì‚¬ìš©
        response = client.models.generate_content(model="gemini-1.5-flash", contents=prompt)
        return response.text.strip()
    except Exception as e:
        log(f"âš ï¸ ìš”ì•½ ì¤‘ ì˜¤ë¥˜(429 ë“±): {e}")
        return "í˜„ì¬ ìš”ì•½ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ì‹œë„í•˜ì„¸ìš”."

def create_driver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36')
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

async def news_release():
    log("ğŸš€ ë‰´ìŠ¤ ë´‡ ì‘ë™ ì‹œì‘")
    sent_urls = load_sent_articles()
    driver = create_driver()

    for company in companies:
        log(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {company}")
        search_url = f'https://search.naver.com/search.naver?where=news&query="{company}"&sm=tab_opt&sort=1'
        driver.get(search_url)
        time.sleep(3) 

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        news_anchors = soup.select('a:has(span.sds-comps-text)')
        log(f"ğŸ“ˆ ë°œê²¬ëœ ë‰´ìŠ¤ ê°œìˆ˜: {len(news_anchors)}")

        for anchor in news_anchors[:2]: # ê³¼ë„í•œ API í˜¸ì¶œ ë°©ì§€ë¥¼ ìœ„í•´ í‚¤ì›Œë“œë‹¹ 2ê°œë¡œ ì œí•œ
            title_tag = anchor.select_one('span.sds-comps-text')
            title = title_tag.get_text(strip=True) if title_tag else ''
            url = anchor.get('href', '').strip()

            if not title or not url or url in sent_urls: continue
            if any(word in title for word in exceptionalWords): continue
            if any(site in url for site in exceptionalSites): continue

            log(f"âœ¨ ìƒˆ ë‰´ìŠ¤ ë°œê²¬ ë° ìš”ì•½ ì‹œë„: {title}")
            content = get_article_content(driver, url)
            
            # AI ìš”ì•½ í˜¸ì¶œ (ì•ˆì— sleep 6ì´ˆê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤)
            summary = await get_summary(title, content)
            
            message = f"ğŸ“¢ [{company}]\nğŸ“Œ {title}\n\nğŸ¤– AI ìš”ì•½:\n{summary}\n\nğŸ”— {url}"
            try:
                await bot.send_message(chat_id=CHAT_ID, text=message)
                save_sent_article(url, title)
                sent_urls.add(url)
                log("âœ… ì „ì†¡ ì™„ë£Œ")
            except Exception as e:
                log(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {e}")

    driver.quit()
    log("ğŸ ëª¨ë“  ì‘ì—… ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(news_release())

import asyncio
import os
import csv
import time
import telegram
from google import genai
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

def log(message):
    print(message, flush=True)

# âœ… ì„¤ì •ê°’
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

client = genai.Client(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else None
bot = telegram.Bot(token=TELEGRAM_TOKEN)
csv_file = 'sent_news.csv'

# âœ… ì›ë˜ ì‚¬ìš©í•˜ì‹œë˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
companies = ["ë”ì¦Œ", "dozn", "ì¹´ì¹´ì˜¤ë±…í¬", "ì¹´ì¹´ì˜¤í˜ì´", "ì˜¤í”ˆì—ì…‹", "ìŠ¤ìœ„ì¹˜ì›"]
exceptionalWords = ['ë­í‚¤íŒŒì´', 'ë³´í˜¸ì', 'ë¸Œëœë“œí‰íŒ', 'ë¸Œëœë“œ í‰íŒ', 'íŠ¸ë Œë“œì§€ìˆ˜', 'íŠ¸ë Œë“œ ì§€ìˆ˜', 'ë§í¬ë“œì¸']
exceptionalSites = ['n.news.naver.com', 'www.pinpointnews.co.kr', 'www.pointdaily.co.kr', 'cwn.kr', 'www.stardailynews.co.kr', 'www.raonnews.com']

def load_sent_articles():
    if not os.path.exists(csv_file): return set()
    sent_set = set()
    with open(csv_file, 'r', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        for row in reader:
            if row: sent_set.add(row[0])
    return sent_set

def save_sent_article(url, title):
    with open(csv_file, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow([url, title])

# âœ… ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_article_content(driver, url):
    try:
        driver.get(url)
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        # ì¼ë°˜ì ì¸ ë‰´ìŠ¤ ë³¸ë¬¸ ì˜ì—­ ì¶”ì¶œ
        paragraphs = soup.find_all(['p', 'div'], class_=['article_body', 'news_con', 'article_view'])
        if not paragraphs: paragraphs = soup.find_all('p')
        content = " ".join([p.get_text(strip=True) for p in paragraphs])
        return content[:2000]
    except:
        return ""

# âœ… AI ìš”ì•½ í•¨ìˆ˜
async def get_summary(title, content):
    if not client: return "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (API í‚¤ í™•ì¸)."
    if len(content) < 100: return "ë³¸ë¬¸ ë‚´ìš©ì´ ì ì–´ ìš”ì•½ì´ ì–´ë µìŠµë‹ˆë‹¤."
    try:
        prompt = f"ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ ì½ê³  3ì¤„ë¡œ ìš”ì•½í•´ì¤˜.\nì œëª©: {title}\në³¸ë¬¸: {content}"
        response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
        return response.text.strip()
    except:
        return "ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def create_driver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36')
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

async def news_release():
    log("ğŸš€ ë‰´ìŠ¤ ë´‡ ì‘ë™ ì‹œì‘")
    sent_urls = load_sent_articles()
    driver = create_driver()

    for company in companies:
        log(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {company}")
        # âœ… ì›ë˜ ì‚¬ìš©í•˜ì‹œë˜ ì¿¼ë¦¬ ë°©ì‹ ê·¸ëŒ€ë¡œ ìœ ì§€ (í°ë”°ì˜´í‘œ í¬í•¨)
        search_url = f'https://search.naver.com/search.naver?where=news&query="{company}"&sm=tab_opt&sort=1'
        driver.get(search_url)
        time.sleep(3) 

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        # âœ… [ë³µêµ¬] ì›ë˜ ì‚¬ìš©í•˜ì‹œë˜ ì„ íƒì ë¡œì§
        news_anchors = soup.select('a:has(span.sds-comps-text)')
        log(f"ğŸ“ˆ ë°œê²¬ëœ ë‰´ìŠ¤ ê°œìˆ˜: {len(news_anchors)}")

        for anchor in news_anchors[:3]: # ìµœì‹  3ê°œë§Œ í™•ì¸
            title_tag = anchor.select_one('span.sds-comps-text')
            title = title_tag.get_text(strip=True) if title_tag else ''
            url = anchor.get('href', '').strip()

            if not title or not url or url in sent_urls: continue
            if any(word in title for word in exceptionalWords): continue
            if any(site in url for site in exceptionalSites): continue

            log(f"âœ¨ ìƒˆ ë‰´ìŠ¤ ì²˜ë¦¬ ì¤‘: {title}")
            
            # ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸° ë° ìš”ì•½
            content = get_article_content(driver, url)
            summary = await get_summary(title, content)
            
            message = f"ğŸ“¢ [{company}]\nğŸ“Œ {title}\n\nğŸ¤– AI ìš”ì•½:\n{summary}\n\nğŸ”— {url}"
            
            try:
                await bot.send_message(chat_id=CHAT_ID, text=message)
                save_sent_article(url, title)
                sent_urls.add(url)
                log(f"âœ… ì „ì†¡ ì„±ê³µ")
                await asyncio.sleep(2)
            except Exception as e:
                log(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {e}")

    driver.quit()
    log("ğŸ ëª¨ë“  ì‘ì—… ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(news_release())
